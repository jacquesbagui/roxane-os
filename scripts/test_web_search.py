#!/usr/bin/env python3
"""
Roxane OS - Test Robust Web Search Module
Script pour tester le module de recherche web robuste
"""

import asyncio
import sys
import time
from pathlib import Path

# Ajouter le rÃ©pertoire parent au path pour les imports
sys.path.append(str(Path(__file__).parent.parent))

import yaml
from loguru import logger
from core.cache import RedisCacheManager
from core.modules.robust_web_search import RobustWebSearchModule


async def test_web_search_performance():
    """Teste les performances du module de recherche web robuste"""
    try:
        # Charger la configuration
        config_path = Path(__file__).parent.parent / "config" / "system.yaml"
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        logger.info("ğŸš€ Test du module de recherche web robuste...")
        
        # Initialiser Redis
        redis_manager = RedisCacheManager(config['database']['redis'])
        redis_success = await redis_manager.initialize()
        
        if not redis_success:
            logger.warning("âš ï¸ Redis non disponible, utilisation sans cache")
            redis_manager = None
        
        # Initialiser le module de recherche web
        web_search_module = RobustWebSearchModule(
            config=config['web_search'],
            redis_cache=redis_manager
        )
        
        # Initialiser le module
        init_success = await web_search_module.initialize()
        if not init_success:
            logger.error("âŒ Ã‰chec de l'initialisation du module")
            return False
        
        # Test de performance
        query = "intelligence artificielle 2024"
        
        # Test 1: Recherche simple
        logger.info("ğŸ“ Test 1: Recherche simple...")
        start_time = time.time()
        
        result = await web_search_module.execute('search', {
            'query': query,
            'max_results': 5
        })
        
        search_time = time.time() - start_time
        
        if result.success:
            logger.info(f"âœ… Recherche effectuÃ©e en {search_time:.3f}s")
            logger.info(f"ğŸ“Š RÃ©sultats: {len(result.data['results'])} trouvÃ©s")
            logger.info(f"ğŸ” Sources: {result.data.get('engines_used', [])}")
        else:
            logger.error(f"âŒ Recherche Ã©chouÃ©e: {result.error}")
        
        # Test 2: Recherche multi-moteurs
        logger.info("ğŸ“ Test 2: Recherche multi-moteurs...")
        start_time = time.time()
        
        result = await web_search_module.execute('multi_search', {
            'query': query,
            'max_results': 3
        })
        
        multi_search_time = time.time() - start_time
        
        if result.success:
            logger.info(f"âœ… Recherche multi-moteurs en {multi_search_time:.3f}s")
            logger.info(f"ğŸ“Š RÃ©sultats: {len(result.data['results'])} trouvÃ©s")
            logger.info(f"ğŸ” Sources totales: {result.data.get('total_sources', 0)}")
            logger.info(f"ğŸ“ SynthÃ¨se: {result.data.get('synthesis', '')[:200]}...")
        else:
            logger.error(f"âŒ Recherche multi-moteurs Ã©chouÃ©e: {result.error}")
        
        # Test 3: Extraction de contenu
        if result.success and result.data['results']:
            logger.info("ğŸ“ Test 3: Extraction de contenu...")
            start_time = time.time()
            
            first_result = result.data['results'][0]
            extract_result = await web_search_module.execute('extract', {
                'url': first_result['url']
            })
            
            extract_time = time.time() - start_time
            
            if extract_result.success:
                logger.info(f"âœ… Contenu extrait en {extract_time:.3f}s")
                logger.info(f"ğŸ“Š Longueur: {extract_result.data['content_length']} caractÃ¨res")
                logger.info(f"ğŸ“ Titre: {extract_result.data['metadata']['title']}")
                logger.info(f"ğŸ”— Liens importants: {len(extract_result.data['important_links'])}")
            else:
                logger.error(f"âŒ Extraction Ã©chouÃ©e: {extract_result.error}")
        
        # Test 4: RÃ©sumÃ© de contenu
        if 'extract_result' in locals() and extract_result.success:
            logger.info("ğŸ“ Test 4: RÃ©sumÃ© de contenu...")
            start_time = time.time()
            
            summarize_result = await web_search_module.execute('summarize', {
                'content': extract_result.data['content'],
                'max_length': 300
            })
            
            summarize_time = time.time() - start_time
            
            if summarize_result.success:
                logger.info(f"âœ… Contenu rÃ©sumÃ© en {summarize_time:.3f}s")
                logger.info(f"ğŸ“Š Compression: {summarize_result.data['compression_ratio']:.2%}")
                logger.info(f"ğŸ“ RÃ©sumÃ©: {summarize_result.data['summary'][:200]}...")
            else:
                logger.error(f"âŒ RÃ©sumÃ© Ã©chouÃ©: {summarize_result.error}")
        
        # Test 5: Performance avec plusieurs requÃªtes
        logger.info("ğŸ“ Test 5: Performance avec plusieurs requÃªtes...")
        start_time = time.time()
        
        queries = [
            "machine learning",
            "deep learning",
            "neural networks",
            "computer vision",
            "natural language processing"
        ]
        
        tasks = []
        for query_test in queries:
            task = web_search_module.execute('search', {
                'query': query_test,
                'max_results': 3
            })
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        multi_query_time = time.time() - start_time
        
        successful_searches = sum(1 for r in results if isinstance(r, dict) and r.get('success'))
        logger.info(f"âœ… {len(queries)} requÃªtes en {multi_query_time:.3f}s")
        logger.info(f"ğŸ“Š SuccÃ¨s: {successful_searches}/{len(queries)}")
        logger.info(f"ğŸ“Š Temps moyen par requÃªte: {multi_query_time/len(queries):.3f}s")
        
        # Test 6: Statistiques
        logger.info("ğŸ“ Test 6: Statistiques...")
        stats = web_search_module.get_stats()
        
        logger.info("ğŸ“Š Statistiques du module de recherche web:")
        for key, value in stats.items():
            logger.info(f"  {key}: {value}")
        
        # Test 7: Informations du module
        logger.info("ğŸ“ Test 7: Informations du module...")
        info = web_search_module.get_info()
        
        logger.info("ğŸ“Š Informations du module:")
        for key, value in info.items():
            if key != 'stats':
                logger.info(f"  {key}: {value}")
        
        # Nettoyage
        await web_search_module.cleanup()
        if redis_manager:
            await redis_manager.cleanup()
        
        logger.success("âœ… Test du module de recherche web robuste terminÃ© avec succÃ¨s")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors du test: {e}")
        return False


async def main():
    """Fonction principale"""
    success = await test_web_search_performance()
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
